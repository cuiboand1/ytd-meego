#Outline/Abstract of Article for http://appdeveloper.intel.com/en-us/node/2406

**( nb: ROUGH DRAFT WORK IN PROGRESS)**

= Overview  = 

The youtube-direct for meego application integrates a number of
traditionally separate applications: a video recorder/still photo camera,
GPS integration and geotagging, combined with managing/uploading captured
media to Youtube-Direct sites. Organizations seeking public contribution by
"[http://gigaom.com/video/youtube-direct-abc7/ citizen journalists]" use
these sites to facilitate content collection from an increasing population
of video-enabled smart-phone users.

YTD-Meego represents an innovative use of the handheld platform as a
computational video camera, performing a unique combination of
functionality that wasn't possible prior to the confluence of cellular
networking integrated with handheld/touchscreen computer and video
camera. 

The implementation of the application is innovative, utilizing "Qt Quick"
technology for rapdid-prototyping dynamic, modern touch GUIs. Qt Quick and
QML is used to implement most of the functionality of this project,
utilizing prototype-based OOP in the !JavaScript language. However, there
are areas where plugins or native access to underlying platform
functionality is not available in QML. In these cases, "hybrid programming"
technique will be used, implemented in C++ using !QtMobility API, but
providing high-level !JavaScript calls for use by QML files.

This article describes the architecture and design decisions porting the
[http://youtube-direct.googlecode.com Youtube-Direct]
handheld application for the
[http://ytd-iphone.googlecode.com Iphone]
/
[http://ytd-android.googlecode.com Android] to
[http://meego.com MeeGo], using
Qt Quick/QML
for the UI, and additional C++ extensions for
handling HD video capture, geotagging, and uploading to a youtube-direct
enabled website. 
As http://ytd-meego.googlecode.com is a new project, part of the purpose of
this article is to solicit feedback, contributors and domain-expertise on
the architecture choices described.

= !YouTube Direct =

 [http://code.google.com/p/youtube-direct/wiki/ArchitectureOverview http://youtube-direct.googlecode.com/files/ytd_architecture_diagram.png]

http://code.google.com/p/youtube-direct/wiki/GettingStarted

Web Demo: http://ytd-demo.appspot.com/test.html

[http://ureport.abc7news.com http://nielsmayer.com/ytd/Abc7-UReport-SmallSize.png][http://ytd-android.googlecode.com http://ytd-android.googlecode.com/files/ytd-screenshot-sm.png]


= Related Work = 

The Maemo Linux platform for the Nokia N900 has several !YouTube uploader
applications. These are not !YouTube direct clients, but do represent
existing applications that support mobile uploading of videos to !YouTube.

 * [http://store.ovi.com/content/39065?clickSource=publisher+channel Nokia YouTube uploader for Maemo/n900]
  * The !YouTube Uploader allows you to directly upload videos to !YouTube when using the Share functionality from the Camera (as a video recorder) or from the Media Player on your Nokia N900.   Video uploads only.

 * [http://blog.pixelpipe.com/2009/10/17/enabling-the-nokia-n900-to-the-social-web-with-pixelpipe/ PixelPipe for Maemo/N900]
  * Upload directly from N900 camera and gallery applications.
  * Background uploads. 
  * Use N900′s Tag Cloud to send to specific services at the time of upload.
    
== Overlap with Maemo 5 and !MeeGo 1.2 Sharing Framework ==

The Nokia !YouTube uploader application mentioned above uses the platform
sharing facilities from Maemo.  There is also significant overlap between
ytd-meego and upcoming !MeeGo 1.2 infrastructure's "Sharing Framework." As
mentioned in http://wiki.meego.com/Architecture#Upcoming_Features , the
"Sharing framework provides a unified API for sharing files via, e.g., BT,
email, web services. It includes webupload engine and an API for transfer
UI." Similar overlap exists with authentication, in that the sharing framework has
"Full integration with
[http://gitorious.org/accounts-sso/pages/Overview_of_accounts_framework Accounts] and
[http://gitorious.org/accounts-sso/pages/Home Single Sign-on]
in !MeeGo.com."

The predecessor (an equivalent diagram couldn't be found for !MeeGo at time of writing)
[http://wiki.maemo.org/Documentation/Maemo_5_Developer_Guide/Architecture/Imaging_and_Sharing Maemo Sharing Framework]
provides media uploading to a variety of services:

 [http://wiki.maemo.org/images/0/0b/SharingAccounts.png]

The Maemo sharing GUI allows for any media captured on the device to be
selected and reliably uploaded to any provider that implements a
[http://wiki.maemo.org/Documentation/Maemo_5_Developer_Guide/Using_Data_Sharing/Sharing_Plug-in sharing plugin]:

 [http://wiki.maemo.org/images/4/49/SharingDialogInterface.png]

In the future, a well integrated youtube-direct "sharing plugin" written
for the !MeeGo Sharing Framework could subsume the functionality of
ytd-meego: allowing arbitrary camera/video apps to output media for
sharing, and allowing the sharing framework to handle the particulars of
uploading that media to a given internet sharing service.

Perhaps a "2.0" version of YTD-!MeeGo could be implemented as a custom
plugin for the !MeeGo Sharing Framework, assuming metadata such as
geotagging and notations are appropriately added to captured media. The
"assignment sheet" from youtube-direct sites is a dynamic source of "tags"
that the user must select and apply to the uploaded media as well. The
framework provides the following features to the handset platform:

 * [http://bugs.meego.com/show_bug.cgi?id=8179 FEATURE: Share UI: Unified entry point to select a destination]
  * Share UI that provides unified method for sharing different types of objects:
   # File paths
   # Tracker IRIs for file-backed ontologies
   # Data URL-encoded objects (RFC 2397)
  * Displays sharing plugins supported by Web upload engine
  * Provides flexibility in destination methods implementation, by allowing multiple sharing methods per plugin and methods to dynamically change during execution
  * Provides full integration with Accounts and Single Sign-on in !MeeGo.com 

 * [http://bugs.meego.com/show_bug.cgi?id=8180 FEATURE: Share: Web Upload Engine]
  * Web Upload Engine that provides unified processing of uploads, including:
   # Upload job queues
   # Resizing of still images
   # Metadata removal/replacement for images and videos
   # Upload recovery after crashes/restart of the device
   # Optional: video re-encoding
  * Provides reference share plugins for Facebook, YouTube, Picasa and Email
  * Full integration with Accounts and Single Sign-on in !MeeGo.com
  * Process separation for upload plugins and integrated with Security Framework 

 * [http://bugs.meego.com/show_bug.cgi?id=8181 FEATURE: Transfer UI: Common transfer management]
  * Transfer UI that provides integrated transfer visualization for all types of transfers:
   # Uploading content to social networks (such as Facebook)
   # Sharing to other devices (e.g. via Bluetooth)
   # Downloading content via different applications (e.g. Browser, Feeds)
   # Synchronizations (e.g. email, contacts, calendar)
  * Transfer UI provides common actions for all types of transfers
  * Transfer history preservation in Tracker; to ensure easy way to establish relationship between services and data and enablers for relevancy tracking

= GUI Technology: Qt Quick and QML = 

== Declarative GUIs and QML ==

Introduce strategy of mostly QML with a C++ or Pyside for heavy lifting and QtMobility functionality.

The overarching design goal of this application is to use "Qt Quick" to
create this application using both "rapid prototyping" while also employing
visually-rich&dynamic, touch&gesture capable interfaces that can be
accomplished in QML.

This project's strategy is to reuse existing functionality and examples from
!QtMobility to get the application running on Meego as quickly, reliably,
and with least effort/code. Issues of efficiency will be considered
"secondary" in that should performance issues arise in testing, they can be
resolved by recoding prototype interpreted code (either Pyside or QML) into
C++.

One of the reasons for considering Pyside and not going directly to C++ is
the comprehensive set of interfaces to QtMobility provided by Pyside. For example

[http://www.pyside.org/docs/pyside-mobility/QtMobility/Location/QGeoPositionInfoSource.html]
. Using Qt Quick

== Details on Hybrid Programming in Pyside and QML ==

http://developer.qt.nokia.com/wiki/Using_QtMobility_sensors_and_QML_from_PySide



== Details on Hybrid Programming in C++ and QML == 

For details, see [http://doc.trolltech.com/4.7/index.html The latest documentation on Qt]; 
[http://doc.qt.nokia.com/4.7/qml-extending.html "Extending QML in C++"], which has special section on calling qtscript back out of C++  [http://doc.qt.nokia.com/4.7/scripting.html#reacting-to-c-objects-signals-in-scripts "Reacting to C++ Objects Signals in Scripts"].

Marko Mattila has blogged about his
[http://zchydem.enume.net/2010/04/08/my-first-qt-quick-app-quickflickr/ experience in creating a hybrid QML/C++ application],
[http://gitorious.org/quickflickr/quickflickr/trees/master quickflickr]
which suggests the following architecture for a Qt Quick application:
 * "Heavy lifting" in C++ and w/ !QtMobility.
  * Not all !QtMobility facilities have QML counterparts so many will need to be "wrapped" in C++ and made available to the QML-level as a high-level call.
  * Needed for  video recording and media capture since http://apidocs.meego.com/1.0/qtmobility/multimedia.html has no QML faciities for media capture.
 *  QML for eye candy:
  * "there are developers implementing the “difficult stuff” in C++ side and then the UI designers do the eye-candy UIs using QML. In my opinion, many of the QML examples and demos do little bit too much in the QML side, such as they implement too much stuff using the !JavaScript. On the other hand, I understand that the idea of demos is to demonstrate the power of QML, but I’m not sure how much designers would like work with !JavaScript."
 *  QML side only visualizes the data that comes from C++
  * don't implement too much logic in QML side.
 *  QML calls C++ interfaces get data back from C++-side.
 *  C++ provides data-models for rendering via QML
  * e.g.  display content of a model in a Flickable [http://doc.qt.nokia.com/4.7/qml-listview.html ListView] only with a few lines of code:  a [http://doc.qt.nokia.com/4.7/qml-listview.html ListView] item and delegate item. 
 *  C++ side creates UI by using [http://doc.qt.nokia.com/4.7/qdeclarativeview.html QDeclarativeView] used for loading the main QML component constructing the UI.
  * The [http://doc.qt.nokia.com/4.7/qdeclarativeview.html QDeclarativeView] is also used for accessing [http://doc.qt.nokia.com/4.7/qdeclarativeengine.html QDeclarativeEngine] and the root context.

Mattila concludes with [http://zchydem.enume.net/2010/09/07/quickflickr-available-at-extras-testing/ lessons learned]:
 * [http://doc.qt.nokia.com/4.7/qml-xmllistmodel.html XmlListModel] doesn’t handle everything yet. It will be improved to support e.g. lists
 * Think when you are implementing delegates! QML is so easy to use that you can accidentally make stupid design decisions e.g. adding a one webview for each delegate:)
 * If something is not visible, then you don’t necessarily  need to create object, or start loading content from a web. Remember this is not always the case e.g. to give better UX you might need to define buffer for [http://doc.qt.nokia.com/4.7/qml-listview.html ListView]s so that they know when to start loading images.
 * Prefer to use  models like [http://doc.qt.nokia.com/4.7/qml-xmllistmodel.html XmlListModel] or [http://doc.qt.nokia.com/4.7/qabstractitemmodel.html QAbstractItemModel] instead of using custom made models e.g. QList<QObject...>. I made this mistake and after removing the custom model and moving to use [http://doc.qt.nokia.com/4.7/qml-xmllistmodel.html XmlListModel], I could get rid of hundreds of lines of C++ code.
 * Think well the C++ interface that is exposed to QML side. After I re-factored the C++ interface, the development cycle of adding a new flickr interface call and building the QML UI on top of that shortened remarkable.
 * On N900 I have problems to make Image element to load images. Everything else seems to work over the network, but occasionally Images just don’t get loaded.
 * Use QML if you want to  do your UI quickly!

== "Rapid prototyping" in QML, Pyside and eventually C++  ==

Leaving stub implementations for parts that'll need to be done in C++ in a separate "making it real" phase.
This includes camera control parts, etc.

Consider also that some functionality might be available in python, and
there is the possibility of substituting python for C++ as the "heavy
lifting" programming language.

== GUI Components in Qt Quick == 

Qt Quick and QML don't provide a "widget" set in the traditional sense. If
one wants to develop with a certain look and feel, that is to be embodied
in the widget set itself, rather than being a part of Qt Quick or QML. This
flexibility can be problematic for rapid prototyping because there's no
"one right way to do things" and there are few reusable components or
patterns to help developers started. Qt Quick however, makes it easier to
implement UI designers Photoshop work and turn it into a real user
interface: http://labs.qt.nokia.com/2010/10/19/exporting-qml-from-photoshop-and-gimp/ .

However, with this flexibility, easy adherence to "user interface design
guidelines" is pushed to the GUI components used. These components are
manufacturer specific with Qt Quick, and embodied within separate
public/open and private GUI components: Qt Quick Colibri and Qt Quick
Compoents.

A public project,
[https://projects.forum.nokia.com/colibri Qt Quick Colibri]
is designed to provide reusable UI components suitable for
cross-platform use on Symbian, Maemo, Meego and Windows/Mac/Linux desktop
environments. It is designed to get developers started
with cross-platform Qt Quick / QML application development. Colibri
currently includes basic components such as buttons, scrollbars, and
sliders, and a few more advanced ones like histograms and album carousel.

In the future, correct "native" and platform-specific look-and-feel will be
provided by
[http://developer.qt.nokia.com/wiki/Qt_Quick_Components Qt Quick Components],
which will bring cross platform components to QML, as an official Nokia
funded project to provide a consistent "native user experience" on Nokia
mobile platforms.

YTD-Meego will use whatever components, probably from Colibri, that will
help get the project off the ground as rapidly as possible, with the least
amount of code. The GUI needs of the YTD-Android application are
rudimentary "data browsers" combined with the usual buttons, menus,
etc. The data structures in YTD-Meego are designed to allow easy
presentation via preexisting
[http://doc.qt.nokia.com/4.7/qdeclarativemodels.html QML Declarative Data models],
such as:

 * [http://doc.qt.nokia.com/4.7/src-imports-folderlistmodel.html Folder List Model]

 [http://doc.qt.nokia.com/4.7/images/declarative-folderlistmodel.png]

 * [http://doc.qt.nokia.com/4.7/qml-xmllistmodel.html XML List Model]

 [http://doc.qt.nokia.com/4.7/images/qml-xmllistmodel-example.png]

 * [http://doc.qt.nokia.com/4.7/qml-listmodel.html List Model] and [http://doc.qt.nokia.com/4.7/qml-listelement.html List Element]

 [http://doc.qt.nokia.com/4.7/images/listmodel.png]

 * [http://doc.qt.nokia.com/4.7/qml-visualitemmodel.html Visual Item Model]

 [http://doc.qt.nokia.com/4.7/images/visualitemmodel.png]

== Browsing Captured Media in Meego Document Gallery ==

The [http://projects.gnome.org/tracker/ Tracker Subsystem] in Meego
provides
[http://linux.die.net/man/5/tracker.cfg configurable]
indexing, meta-data extraction, and search capabilities for a variety of
data types. Tracker is a central repository for files and media, allowing data-sharing between applications,
while enabling
[http://en.wikipedia.org/wiki/Semantic_search "Semantic Search"]
via
[http://www.w3.org/RDF/ RDF]-based [http://en.wikipedia.org/wiki/Ontology ontologies].
When storing captured media, Tracker is used for tagging media files with
meta-data, including Geolocation data.

The Meego Document Gallery, where videos and associated metadata are stored
for use by applications, has a QML interface available in !QtMobility 1.2.  The
[http://doc.qt.nokia.com/qtmobility-1.2.0-tp1/qml-gallery.html Gallery QML Plugin]
from "preview release" !QtMobility 1.2 provides this functionality. The 
[http://doc.qt.nokia.com/qtmobility-1.2.0-tp1/qml-documentgalleryitem.html QML DocumentGalleryItem Element]
is where the file-type, e.g. video, is stored, the "progress" percentage in
uploading/downloading, alongside other file metadata. In conjunction with a
[http://doc.qt.nokia.com/qtmobility-1.2.0-tp1/qml-documentgallerymodel.html QML DocumentGalleryModel Element],
the following QML browses image documents in the gallery using this functionality:
{{{
     import Qt 4.7
     import QtMobility.gallery 1.1
    
     Rectangle {
         width: 1024
         height: 768
    
         GridView {
             anchors.fill: parent
             cellWidth: 128
             cellHeight: 128
    
             model: DocumentGalleryModel {
                 rootType: DocumentGallery.Image
                 properties: [ "url" ]
                 filter: GalleryWildcardFilter {
                     property: "fileName";
                     value: "*.jpg";
                 }
             }
    
             delegate: Image {
                 source: url
                 width: 128
                 height: 128
             }
         }
     }
}}}

[http://maemo.gitorious.org/maemo-af/libqttracker A Qt Tracker Library]
allows access to Tracker at the C++ level for any Tracker API's not covered by QML.

Note that Tracker is part of the not-yet-final Meego 1.2 Sharing Framework.
Yet to be completed features -- "Transfer history preservation in Tracker;
to ensure easy way to establish relationship between services and data." --
indicate unimplemented functionality:
 * [http://bugs.meego.com/show_bug.cgi?id=8181 FEATURE: Transfer UI: Common transfer management]
 * [http://bugs.meego.com/show_bug.cgi?id=8179 FEATURE: Share UI: Unified entry point to select a destination].

== !MeeGo !GeoClue Subsystem for Geolocation data ==

!MeeGo provides [http://www.freedesktop.org/wiki/Software/GeoClue GeoClue] for location services such as GPS, GSM Cell and
Wifi Network. The appropriate API for YTD-Meego is
[http://doc.qt.nokia.com/qtmobility-1.2.0-tp1/location-overview.html Qt Mobility's Location API]
which provides a C++ programming interface. A
[http://wiki.forum.nokia.com/index.php/Qt_C%2B%2B_and_QML_integration,_context_properties_and_GPS_compass Hybrid C++/QML example of using GPS]
provides examples showing how this functionality is coded with !QtMobility 1.0.

YTD-Meego will seek to use the !QtMobility 1.2
[http://doc.qt.nokia.com/qtmobility-1.2.0-tp1/qml-location-plugin.html QML
Location Plugin] which provides high-level QML access to location data,
hopefully at a sufficient level that further hybrid C++ coding will not be
necessary. Unfortunately, this facility is not available, even in the just
released [http://labs.qt.nokia.com/2010/12/24/qt-mobility-1-2-technology-preview/ QtMobility 1.2 technology preview]:
"Location: Geoclue backend code is not enabled in TP package. (enabled in master code line)"

Compared to the complexities of the hybrid programming needed with
!QtMobilility 1.0, the QML-only approach of !QtMobility 1.2 is much more
concise. The
[http://doc.qt.nokia.com/qtmobility-1.2.0-tp1/qml-positionsource.html QML PositionSource Element]
snippet below retrieves [http://en.wikipedia.org/wiki/NMEA NMEA] format GPS data entirely in QML:

{{{
     import Qt 4.7
     import QtMobility.location 1.1
    
     Rectangle {
             id: page
             width: 350
             height: 350
             PositionSource {
                 id: positionSource
                 updateInterval: 1000
                 active: true
                 // nmeaSource: "nmealog.txt"
             }
             Column {
                 Text {text: "<==== PositionSource ====>"}
                 Text {text: "positioningMethod: "  + printableMethod(positionSource.positioningMethod)}
                 Text {text: "nmeaSource: "         + positionSource.nmeaSource}
                 Text {text: "updateInterval: "     + positionSource.updateInterval}
                 Text {text: "active: "     + positionSource.active}
                 Text {text: "<==== Position ====>"}
                 Text {text: "latitude: "   + positionSource.position.coordinate.latitude}
                 Text {text: "longitude: "   + positionSource.position.coordinate.longitude}
                 Text {text: "altitude: "   + positionSource.position.coordinate.altitude}
                 Text {text: "speed: " + positionSource.position.speed}
                 Text {text: "timestamp: "  + positionSource.position.timestamp}
                 Text {text: "altitudeValid: "  + positionSource.position.altitudeValid}
                 Text {text: "longitudeValid: "  + positionSource.position.longitudeValid}
                 Text {text: "latitudeValid: "  + positionSource.position.latitudeValid}
                 Text {text: "speedValid: "     + positionSource.position.speedValid}
             }
             function printableMethod(method) {
                 if (method == PositionSource.SatellitePositioningMethod)
                     return "Satellite";
                 else if (method == PositionSource.NoPositioningMethod)
                     return "Not available"
                 else if (method == PositionSource.NonSatellitePositioningMethod)
                     return "Non-satellite"
                 else if (method == PositionSource.AllPositioningMethods)
                     return "All/multiple"
                 return "source error";
             }
     }
}}}

== Reusing !QtMobility 1.2's "declarative camera" Example ==

[http://doc.qt.nokia.com/qt-mobility/declarative-camera.html QtMobility's declarative camera demo]
will form the basis for the "camera" parts of YTD-direct. Unfortunately,
similar to the situation with GPS data above, the camera is not yet
functional in the
[http://labs.qt.nokia.com/2010/12/24/qt-mobility-1-2-technology-preview/ Qt Mobility 1.2 Technology Preview]:
"qml_camera does not display an image." See the system architecture
section, below, titled "!QtMobility 1.2 and the N900 Camera Component."

However, the "declarative camera" example will be added to YTD-meego as a
"stub" implementation, allowing prototyping of the GUI and the camera
interface part of the application. The example would be modified so that
the camera frame would come up when the application is put into
video-shooting mode, and instead of quitting camera mode, the user would be
returned to the application's top-level. The example
[http://doc.qt.nokia.com/qt-mobility/declarative-camera-declarative-camera-qml.html QML-based GUI and code]
creates a camera GUI like this:

 [http://doc.qt.nokia.com/qt-mobility/images/qml-camera.png]

Below, a snippet of code associated with the "declarative camera", to give
an exampe of the high-level programming associated with QML:

{{{
     PhotoPreview {
         id : photoPreview
         anchors.fill : parent
         onClosed: cameraUI.state = "PhotoCapture"
         focus: visible

         Keys.onPressed : {
             //return to capture mode if the shutter button is touched
             if (event.key == Qt.Key_CameraFocus) {
                 cameraUI.state = "PhotoCapture"
                 event.accepted = true;
             }
         }
     }

     Camera {
         id: camera
         x : 0
         y : 0
         width : 640
         height : 480
         focus : visible //to receive focus and capture key events
         flashMode: stillControls.flashMode
         whiteBalanceMode: stillControls.whiteBalance
         exposureCompensation: stillControls.exposureCompensation

         onImageCaptured : {
             photoPreview.source = preview
             stillControls.previewAvailable = true
             cameraUI.state = "PhotoPreview"
         }
     }
}}}

== Authentication and Access Control in QML == 
 
http://code.google.com/apis/youtube/articles/youtube_mobileresources.html#security

Video uploads as well as any other operations that modify or write data
require authorization, which is done through an authentication token
submitted in the API request.
[http://code.google.com/apis/youtube/2.0/developers_guide_protocol_clientlogin.html# ClientLogin]
is the simplest method to use for mobile applications. For example, the YTD-Android application, uses the
[http://developer.android.com/reference/android/accounts/AccountManager.html Android AccountManager]
to  obtain authentication tokens. An alternative and preferred standard is
[http://code.google.com/apis/youtube/2.0/developers_guide_protocol_oauth.html OAuth]
, for which http://gdata-java-client.googlecode.com/ is an example Java client.

An example OAuth implementation using QML can be found at 
http://gitorious.org/qt-qml-demo-playground/qt-qml-demo-playground/trees/master/twitter-oauth for example:
http://gitorious.org/qt-qml-demo-playground/qt-qml-demo-playground/blobs/master/twitter-oauth/TwitterCore/OAuth.js
http://gitorious.org/qt-qml-demo-playground/qt-qml-demo-playground/blobs/master/twitter-oauth/TwitterCore/OAuth.qml

== JSON RPC in QML ==

The web component of the app will be implemented entirely in QML, using Youtube-Direct's JSON API: 
 * http://code.google.com/p/youtube-direct/wiki/YTDAdminJSONAPI
  * In YTD v2.0, the admin backend is complemented with a JSON-RPC API that enables you to fetch all the data relating to assignments, submissions and configuration programmatically.
  * The admin API is based on the JSON-RPC protocol format. It is essentially a REST-ful POST request with a JSON payload. For more information on JSON-RPC - http://en.wikipedia.org/wiki/JSON-RPC.

http://bugreports.qt.nokia.com/browse/QTBUG-12117 suggests a JSON data
model for QML suggests a "design pattern" as workaround:

     It would be very convenient to have a JSON data model to use with QML's
     list view elements, instead of emulating a model using !XMLHttpRequest,
     regular !JavaScript JSON support and !ListModel. For example:
{{{
     Item {
         ListModel { id: listmodel }
         onCompleted: {
             var xhr = new XMLHttpRequest;
             xhr.open("GET", "http://service.com/api");
             xhr.onreadystatechange = function() {
                 if (xhr.readyState == XMLHttpRequest.DONE) {
                     var a = JSON.parse(xhr.responseText);
                     for (var b in a) {
                         var o = a[b];
                         listmodel.append({name: o.name, url: o.url});
                     }
                 }
             }
             xhr.send();
         }
     }
}}}

The above pattern is an example of how the interface to the !YouTube Direct
assignment feed in YTD-Meego could be implemented.  Essentially, an
assignment feed is an RSS feed. An example of an Qt Quick application using
such a feed is a
[https://projects.forum.nokia.com/QtQuickTwitterExample Qt-Quick "twitter' client]
.  This constructs a data model that can be browsed by the
QML "XML List Model" introduced above:
[https://projects.forum.nokia.com/QtQuickTwitterExample/browser/twitter/content/TwitterModel.qml QtQuickTwitterExample Data Model]
displaying the data present in the RSS in a GUI:

 [https://projects.forum.nokia.com/QtQuickTwitterExample/raw-attachment/wiki/WikiStart/Twitter-listview1.png]

A similar integration of QML models and JSON/RPC data from a webserver is
the XBMC Remote for the [http://xbmc.org/ X Box Media Center], which itself
has already been [http://www.madeo.co.uk/?page_id=605 ported to MeeGo]:

 * http://gitorious.org/xbmc-qml-remote 
 * http://gitorious.org/xbmc-qml-remote/pages/Home

 [http://web2.0-apps.de/fabian/xbmc/screenshot/album.jpeg]

Some code examples from that app doing JSON/RPC entirely within QML:

http://gitorious.org/xbmc-qml-remote/xbmc-qml-remote/blobs/master/js/player.js
{{{
Player.prototype.cmd = function(cmd, param) {
        var doc = new XMLHttpRequest();
        doc.onreadystatechange = function() {
                if (doc.readyState == XMLHttpRequest.DONE) {
                        //console.log(doc.responseText);
                }
        }

        doc.open("POST", "http://"+$().server+":" + $().port + "/jsonrpc");
        var str = '{"jsonrpc": "2.0", "method": "'+this.type+'Player.'+cmd+'",';
        if (param) {
                str += param + ","
        }
        str += ' "id": 1}';
        console.log(str);
        doc.send(str);
        return;
}
}}}

http://gitorious.org/xbmc-qml-remote/xbmc-qml-remote/blobs/master/js/library.js
{{{
Library.prototype.loadMovies = function () {
        var doc = new XMLHttpRequest();
        doc.onreadystatechange = function() {
                if (doc.readyState == XMLHttpRequest.DONE) {
                        //console.log(doc.responseText);

                        var result = JSON.parse(doc.responseText).result;
                        var movies = result.movies;
                        for (var i = 0; i < movies.length; i++){
                                //console.log(movies[i].thumb)
                                var thumb = "http://"+$().server+":" + $().port + "/images/DefaultAlbumCover.png";
                                if (movies[i].thumbnail) {
                                        thumb = "http://192.168.0.11:8080/vfs/" + movies[i].thumbnail;
                                }

                                movieModel.append({"id": movies[i].movieid, "name": movies[i].label, "thumb": thumb, "genre":  movies[i].genre, "duration": movies[i].runtime, "rating": movies[i].rating});
                        }
                }
        }

        doc.open("POST", "http://"+$().server+":" + $().port + "/jsonrpc");
        var str = '{"jsonrpc": "2.0", "method": "VideoLibrary.GetMovies", "params": { "start": 0, "fields": ["genre", "director", "trailer", "tagline", "plot", "plotoutline", "title", "originaltitle", "lastplayed", "showtitle", "firstaired", "duration", "season", "episode", "runtime", "year", "playcount", "rating"] }, "id": 1}';
        doc.send(str);

        return;
 }
}}}

== Resumable Uploading == 

One of the issues with a youtube-direct client, noted in private comment by
Jarek Wilkiewicz of !YouTube, is that the error&retry logic in resumable
uploads need be robust: uploading large files while on the move, over flaky
and shifting networks is nontrivial.  This is handled by the the Youtube
API for resumable uploads (
http://code.google.com/intl/ja/apis/youtube/2.0/developers_guide_protocol_resumable_uploads.html
). YTD-meego must work with this API and provide the retry and
partial-upload logic that is robust in the face of networking challenges.

http://code.google.com/apis/youtube/articles/youtube_mobileresources.html#uploading provides details:

 For mobile applications, [http://code.google.com/apis/youtube/2.0/developers_guide_protocol_resumable_uploads.html#Resumable_uploads direct resumable uploading] is the most reliable choice since it enables an application to gracefully recover from connectivity failures and resume an upload from the point of failure. !YouTube’s resumable uploading protocol leverages the HTTP 1.1 [http://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html#sec14.16 Content-Range/Range] mechanism to transfer videos in chunks and, in the event of an interruption, to identify the number of bytes that were successfully transferred.

 While the actual video content is the most important component in an upload, video metadata is an integral part of the process since that metadata lets users locate videos in search and also enables other features described later in this article. In addition to common elements like a category, description, and title, mobile applications can easily include [http://code.google.com/apis/youtube/2.0/reference.html#GeoRSS_elements_reference geolocation] data from the phone’s GPS device. These data let you provide location-based search or to plot video locations on a map. For video upload applications seeking to minimize user interaction, zero-metadata uploads are another option and more information about that is available from this Google I/O [http://apiblog.youtube.com/2010/06/youtube-api-google-io-2010.html talk].

== The road not taken: Hybrid !WebKit with !XQuery ==

[http://qt.gitorious.org/qt-labs/graphics-dojo/trees/master/videofeed Nokia Qt Labs "videofeed"]
application suggests an alternative implementation strategy that probably
won't be used in this project, but is interesting to consider for this
class of application. The Nokia demo states: "Various video websites like
YouTube, Google Videos, TED provide the list of videos as RSS, Atom. The
demo extracts contents from the RSS using
[http://doc.trolltech.com/4.7/xmlprocessing.html XQuery].
The list of feeds and the
[http://developer.qt.nokia.com/wiki/XQueryTutorials XQuery]
used to extract contents is read in dynamically through
configuration files."

One of the configuration files, 
[http://qt.gitorious.org/qt-labs/graphics-dojo/blobs/master/videofeed/rss/youtube.xq rss/youtube.xq], 
looks like:

{{{
  for $i in doc($uri)/rss/channel/item
      return fn:string-join( (
          $i/title/string(), 
          "author",
          $i/description/string(),
          "subtitle",
          $i/link/string(),
          $i/guid/string(),
          $i/pubDate/string(),
          "duration"
          ), " %%QT_DEMO_DELIM%% ")
}}}

Note that this technique also uses the high-overhead pathway of !WebKit to
NPAPI to Flash just to display video; CSS transitions/animations are used
for display instead of the functionality provided in a "Qt Quick
Components" or "Qt Quick Colibri."  The above implementation also makes use
of !WebKit for offline storage -- which is also an issue ytd-meego will
face. Unfortunately, relying this much on !WebKit is a very high-overhead
way of implementing this functionality. Online discussion on the subject
suggests that each !WebKit instance adds about 10Mb to the application. And
in most cases, the functionality is available natively in Qt, and much of
it via QML.

It might be easiest to do  the "web" part of the app this way,
and enable call-outs to QtMobility for playing or recording media,
geotagging, etc. The existing !YouTube-Direct web-application (see
[http://ytd-demo.appspot.com/test.html web Demo])
could be dropped directly into a !WebKit frame inside the application ...

However,such an implementation ends up being a more breakable,
hard-to-test, heavyweight app using !WebKit. On the other hand, perhaps
such an approach will be needed anyways.  For example: using existing
browser-based authentication; cross-domain authentication from a main 'www'
site to a separate 'ytd' site; and other instances where cross-application
and cross-domain cookies need to be used by the custom handheld
application.


== !QtMobility 1.2 and the N900 Camera Component ==

As the !MeeGo Handset UX platform is under development, some of the media
infrastructure needed by this project is incomplete and not in a usable
state for application developers. In particular, camera functionality and
video recording will not be available until !MeeGo 1.2, to be released April
2011. There are a number of issues delaying camera integration on !MeeGo,
which were clarified in IRC by the N900 hardware adaptation lead Teemu
Tuominen:

     Tuesday, December 14, 2010 11:47:01 pm #meego: theodor:
     currently, the differences in kernel level are ... delaying camera
     integration.. since we have selected to support new architecture that
     cannot be accepted by meego reference kernel due its partly
     experimental.... To fully featurize camera in N900, !MeeGo needs
     components that used to be closed binaries in Maemo side. I assume a
     bunch of 3rdParty agreements needs to be dealt differently with !MeeGo,
     and can only hope that this is ongoing work.

The status of camera and GPS functionality on the n900 were discussed on
12/16/10 meeting on Nokia N900 Hardware Adaptation:

 * http://trac.tspre.org/meetbot/meego-meeting/2010/meego-meeting.2010-12-16-08.00.html
 * http://trac.tspre.org/meetbot/meego-meeting/2010/meego-meeting.2010-12-16-08.00.log.html

The camera features needed by YTD-!MeeGo that are under implementation for !MeeGo 1.2
include:

 * [http://bugs.meego.com/show_bug.cgi?id=5461 FEATURE: Camera] 
  * A Camera application is required to capture still images and record videos with the device.  

 * [http://bugs.meego.com/show_bug.cgi?id=2743 FEATURE: Camera subsystem]
  * !MeeGo to provide [http://linux.bytesex.org/v4l2/ V4L2] for Camera subsystem  
  * Components are required on the kernel side:
   * Media controller core
   * Primary and secondary sensor drivers (et8ek8 and smia-sensor)
   * Flash and lens controller drivers (adp1653 and ad5820)
   * OMAP3 ISP driver (isp-mod)
   * OMAP34xx camera driver (omap34xxcam)
  * Available at http://gitorious.org/omap3camera/mainline

 * [http://bugs.meego.com/show_bug.cgi?id=7623 FEATURE: camerabin support in GStreamer]
  * still image capture with
   * arbitrary post processing
   * zooming
   * various resolutions
  * 3A (autofocus, autowhitebalance and autoexposure)
   * locking 3A settings
  * viewfinder with
   * arbitrary post processing
  * videocapture with
   * arbitrary post processing
   * zooming
   * various resolutions

[http://labs.qt.nokia.com/2010/12/24/qt-mobility-1-2-technology-preview/ Qt Mobility 1.2 Technology Preview]
was just released December 24 2010, so it may be possible to develop and
test for some of the camera functionality ahead of the !MeeGo 1.2
release. Unfortunately, this will not result in a functional camera:
"qml_camera does not display an image." and developers are warned of the
status of this code:
  We would like to share our source package of the Qt Mobility 1.2 APIs at a Technology Preview level of maturity and a set of RPM packages for MeeGo compatible devices. As we communicated earlier, the number one mission for Mobility 1.2 was to deliver backend support for MeeGo, so that has been the primary focus in this release. A lot of work is still on-going and there are known issues in this Technology preview. However, we want to obtain your feedback on the design of new APIs early before we mature the APIs to BETA and then ultimately finalize for our delivery to MeeGo 1.2 in early 2011.

What is useful is that there is
[http://doc.qt.nokia.com/qtmobility-1.2.0-tp1/ documentation on Qt Mobility 1.2]
and that this is available for testing currently with a
[http://download.meego.com/live/devel:/qt-mtf:/qt-mobility:/1.2tp1/testing/ MeeGo repository]
and packages 'qt-mobility' and 'qt-mobility-examples' available for install via zypper.

= N900 Platform and Hardware Overview =

The following diagram describes the
[http://wiki.maemo.org/Documentation/Maemo_5_Developer_Guide/Architecture/Multimedia_Domain Nokia n900 Maemo "Multimedia Domain"],
and should translate, roughly, to !MeeGo on the same platform:

 [http://wiki.maemo.org/images/thumb/5/56/OMAP_architecture.png/800px-OMAP_architecture.png]

http://meego.com/developers/meego-architecture/meego-architecture-domain-view
describes !MeeGo's "Multimedia domain": providing audio and video playback,
streaming, and imaging functionality to the system. It handles retrieval,
demuxing, decoding and encoding, seeking of audio and video data. It
includes the following subsystems under "Media Services" part of Meego Middleware:

 * Gstreamer provides cross platform, plugin-based framework for playback, streaming, and imaging. 
 * !PulseAudio handles audio inputs, post/pre processing, and outputs in a system.
 * Camera subsystem provides still and video camera functionality, including platform specific codecs and containers for GStreamer, metadata, and image post processing.
 * GStreamer-compatible codecs are supported for encoding / decoding of audio and video
 * GUPnP is an object-oriented framework for creating UPnP devices and control points, with extension libraries for IGD and A/V specifications

The source code for these components is located at http://meego.gitorious.org/maemo-multimedia .

== Audio Subsystem ==

The audio subsystem is depicted in the following diagram from
[http://linuxplumbersconf.org/2009/slides/Jyri-Sarha-audio_miniconf_slides.pdf Jyri Sarha's presentation "Practical Experiences from Using Pulseaudio in Embedded Handheld Device"]
from the recent Linux Plumber's Conference:

 [http://nielsmayer.com/meego/N900-Pulseaudio-Configuration.png]

A lively thread on the role of pulseaudio in a handset was started on the [http://lists.linuxaudio.org/listinfo/linux-audio-dev Linux Audio Developers] and [http://lists.meego.com/pipermail/meego-handset/ Meego Handset] Lists, with notable replies by:
 * Marco Ballesio (Nokia Multimedia Architect): [http://lalists.stanford.edu/lad/2010/12/0164.html LAD#1] [http://lalists.stanford.edu/lad/2010/12/0166.html LAD#2]
 * Kai Vehmanen (Nokia Meego Telephony (?) and [http://www.eca.cx/ecasound/ Ecasound] author): [http://lalists.stanford.edu/lad/2010/12/0168.html LAD#3] [http://lalists.stanford.edu/lad/2010/12/0167.html LAD#4 ] [http://lalists.stanford.edu/lad/2010/12/0170.html LAD#5]

== Video and Camera Subsystem == 

The video subsystem, Gstreamer and Camera adaptation diagaram goes here.

== Meego Policy Framework ==

[http://wiki.meego.com/images/Meego-policy-framework-developer-guide.pdf http://nielsmayer.com/ytd/meego-policy-framework.png]

Marco Ballesio's,
[http://conference2010.meego.com/session/policy-framework-flexible-way-orchestrate-multiple-functionalities-meego-devices Policy Framework: A Flexible Way To Orchestrate Multiple Functionalities On MeeGo Devices]
from the !MeeGo 2010 conference outlines the role of the !MeeGo
[http://wiki.meego.com/images/Meego-policy-framework-developer-guide.pdf "Policy Framework"]:

 Functionalities like phone, camera, media player or navigator are often combined in !MeeGo devices. Each of them corresponds to a device mode and defines thus an expected behavior pattern. !MeeGo devices are expected to behave according to an active device mode and, as a consequence, the behavior of applications can be device mode dependent. The Policy Framework isolates and offloads as much as possible the mode based logic from the applications, making porting of mainstream desktop applications easy. The offloaded logic includes arbitration of media resource usage, management of media streams (routing, audio muting etc) and assignment of adequate resources in terms of memory and scheduling priority. The Policy Framework also isolates and offloads the HW adaptation from the applications and implements implicit, device mode dependent actions to handle events like calls or messages, improving the end-user-experience on handsets or other devices with slower user interaction mechanisms.

Still to be determined: how would ytd-meego interact with this Policy
Framework on a handset. For example: what happens if a phone call comes in
while you're shooting video? What forms of notifications, or
application-switching, are allowed while ytd-meego is being used? Will using
!QtMobility API automatically make this application compliant?

Similar "Policy Framework" issues include preventing scheduling background tasks while
capturing media. For example a typical
[http://talk.maemo.org/showthread.php?t=61960 complaint over the Tracker subsystem]:

  I would like it to index the new pictures/videos AFTER I've shot them, after LEAVING the application that made them. Not during...
  In general, while I'm doing the creation, I would want as little other system activity as possible. Real multi-tasking on a limited resource device only goes that far ... Ask Apple and Google.
  So while doing time critical stuff, I ideally want all non-critical stuff frozen.
  That would help the stuttering while filming.

= Future work enabled by a "Video 2.0" platform =

The new generation of hybrid video/computing platform such as the Nokia
N900 or N8 enable a whole different world of applications. Stanford
University's
[http://www-graphics.stanford.edu/papers/fcam/ FCam Project ]
claims applications of "[http://www-graphics.stanford.edu/projects/camera-2.0/ Camera 2.0]"
include:
 "high dynamic range imaging, flash-noflash imaging, coded aperture and coded exposure imaging, photography under structured illumination, multi-perspective and panoramic stitching, digital photomontage, all-focus imaging, and light field imaging."

The !YouTube Direct Application on a handset represents the first steps
towards "Video 2.0."  With the veracity of news and video footage always in
question, such platforms can make use of existing platform cryptography
libraries which can be applied to digitally signing an embedded timecode,
geotags and other information embedded in the video. Using cryptography, an
initial "chain of custody" on the video could be established, such as a
specific certificate issued by the news organization that ensures the
platform/software/submitter of the information are not forgeries. By
watermarking digital signatures of GPS geotags and a monotonically
increasing timecode into the video, edits, photoshopping and omissions to
that video become "provable." These are innovative uses of video that can
only be enabled by having a complete and robust mobile computing and
telecommunication platform like Meego built into the "video camera"

= Conclusion =

Youtube-direct on Meego is cool and innovative. Please add your comments,
in the comments section of this article, and if you have something to
contribute to the project, please volunteer. There's a lot of code to write
and a lot of different components to get working and test on this
promising, but evolving platform.

